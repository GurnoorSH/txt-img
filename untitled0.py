# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YwfEXWiY-045kXmaed-YKyH_ftzQtoUw

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
"""

!pip install --upgrade diffusers transformers accelerate safetensors

from huggingface_hub import login

# Paste your HF token here
login("")

from diffusers import StableDiffusionPipeline
import torch

# Load the pre-trained pipeline from Hugging Face
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
    # revision="fp16",
    use_auth_token=True  # required for gated models
).to("cuda")

prompt = " dog by a cat in a while swimming "
image = pipe(prompt, guidance_scale=7.5, num_inference_steps=50).images[0]

# Display the image
image.show()

# Save if needed
image.save("cpe.png")

generator = torch.manual_seed(42)

image = pipe(prompt, guidance_scale=7.5, num_inference_steps=40, generator=generator).images[0]
image.show()

!pip install gradio

import gradio as gr

def infer(prompt, guidance=7.5, steps=50):
    image = pipe(prompt, guidance_scale=guidance, num_inference_steps=steps).images[0]
    return image

gr.Interface(fn=infer,
             inputs=[gr.Text(), gr.Slider(1,20,step=0.5, value=7.5), gr.Slider(10,100,step=10, value=50)],
             outputs="image",
             title="Stable Diffusion Text-to-Image"
).launch()